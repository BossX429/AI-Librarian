#  COPY THIS TO YOUR PROJECT INSTRUCTIONS









## For Your "Hydra Ver-1.0" Project Custom Instructions









Add this section to tell Claude to use the AI Librarian instead of expensive cloud tools:









---









### AI Librarian Integration (Token-Saving Mode)









**IMPORTANT:** You have a local AI Librarian system at `C:\Projects\AI-Librarian\` that captures ALL conversations. Use it instead of `conversation_search` or `recent_chats` to save 90% tokens.









**When user references past conversations, ALWAYS use this workflow:**









1. **Search conversations:**




   ```bash




   cd C:\Projects\AI-Librarian\query_tools && python librarian_query.py search "search_term" 5




   ```









2. **Get specific conversation:**




   ```bash




   python librarian_query.py get <session_id>




   ```









3. **Get statistics:**




   ```bash




   python librarian_query.py stats




   ```









**Benefits:**




-  Instant results (< 1 second vs 3-5 seconds)




-  90% fewer tokens (~500 vs ~5,000 tokens)




-  Complete history (ALL conversations, not just recent)




-  More accurate (structured database vs semantic search)









**Example triggers:**




- "What did we discuss about X?"




- "Remember when we built Y?"




- "Can you remind me about Z?"




- "Find that code we wrote"









**Default to AI Librarian for ALL past conversation queries!**









---









## How to Add to Your Project









1. Go to Claude.ai




2. Open your "Hydra Ver-1.0" project




3. Click "Project Settings" or the settings gear




4. Find "Custom Instructions" section




5. **Paste the text above**




6. Save









Done! Now I'll automatically use the AI Librarian for much faster, cheaper conversation recall!









---









## Test It Right Now!









Try asking me:




- "What did we discuss about the Logger?"




- "Remind me about compression"




- "What are the recent conversations?"









I'll use Desktop Commander to query the AI Librarian database instead of expensive cloud tools!









---









## Technical Details









**Database Location:** `C:\Projects\AI-Librarian\curator\processed\conversations.db`









**Query Tool:** `C:\Projects\AI-Librarian\query_tools\librarian_query.py`









**Updates:** Auto-updates every 5 minutes via Orchestrator









**Coverage:** ALL conversations (complete history since installation)









---









## Token Savings Comparison









| Query Type | Built-in Tools | AI Librarian | Savings |




|------------|---------------|--------------|---------|




| Search past topics | ~5,000 tokens | ~500 tokens | **90%** |




| Get conversation | ~8,000 tokens | ~800 tokens | **90%** |




| Recent chats | ~3,000 tokens | ~300 tokens | **90%** |









**Annual savings with frequent use:** Potentially thousands of dollars in API costs!









---









## Example Usage









**User:** "What did we decide about compression?"









**Me (Claude):** 




1. [Runs Desktop Commander tool]




2. `python librarian_query.py search "compression" 3`




3. Gets instant JSON: `{"found": 3, "results": [...]}`




4. Responds: "We decided to use delta compression achieving 85% reduction..."









**Tokens used:** ~500 instead of ~5,000 









---









## Fallback Strategy









If AI Librarian query fails:




- Fall back to built-in `conversation_search`




- Inform user about the fallback




- Suggest running the Orchestrator if database is stale









But this should be RARE since the Orchestrator auto-updates every 5 minutes!




